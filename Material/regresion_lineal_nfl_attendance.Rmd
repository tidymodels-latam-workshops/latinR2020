---
title: "Regresi칩n con datos de NFL_attendance"
author: "Basado en el blog de Julia Silge"
date: "29/9/2020"
output: 
  html_document:
     theme: "journal"
     dev: png
     highlight: "default"
     toc: true
     toc_float: true
     code_folding: hide
---



```{r librerias-utiles, setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggthemes)
library(hrbrthemes)
theme_set(theme_fivethirtyeight())

```



## Dataset

Utilizaremos los datos de [#Tidytuesday](https://github.com/rfordatascience/tidytuesday), la cual es una iniciativa de la comunidad de R, en la cual se publica semanalmente un set de datos con el objetivo de practicar las habilidades de procesamiento, visualizaci칩n y modelado de datos. El dataset elegido contiene datos de la NFL, liga de f칰tbol americano de USA.

## Lectura de datos

```{r nfl_attandance, include=FALSE}
attendance <- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-04/attendance.csv")
standings <- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-04/standings.csv")

```
```{r vista-dataset}
attendance %>% glimpse()
standings %>%  glimpse()

```


## Uni칩n de los datasets

Ya le칤mos el dataset *attendance* y *standings*:

- attendance: datos de la asistencia semanal de los equipos. 

- standings: datos de la clasificaci칩n de los equipos con sus respectivas marcas. 

A continuaci칩n vamos a unir ambos datasets utilizando la sentencia **left_join** y mediante las siguientes variables: **c("year", "team_name", "team"))**



```{r union_datasets, echo=FALSE, message=FALSE, warning=FALSE}

attendance_joined <- attendance %>%
  left_join(standings,
    by = c("year", "team_name", "team")
  )

attendance_joined %>% view()
```


## Objetivo
Nuestro objetivo es obtener un modelo capaz predecir la asistencia semanal o 'weekly_attendance' a la NFL a partir del conjunto de datos #TidyTuesday. Hasta ahora, sabemos que es necesario utilizar modelos de regresi칩n.


## An치lisis exploratorio inicial

```{r boxplot-inicial, echo=FALSE, message=FALSE, warning=FALSE, fig.height=7, fig.width=10, fig.show = "hold", fig.align='center'}

attendance_joined %>%
  filter(!is.na(weekly_attendance)) %>%
  ggplot(aes(fct_reorder(team_name, weekly_attendance),
    weekly_attendance,
    fill = playoffs)) +
  geom_boxplot(outlier.alpha = 0.5) +
  coord_flip() +
  labs(
    fill = NULL, x = NULL,
    y = "Asistencia semanal de juegos de la NFL"
  )

# playoffs: eliminatorias, columna que contiene 2 posibles valores: eliminado y no eliminado.
```







Tengamos en cuenta que para los 32 equipos de la NFL, existen a침os en que lo dieron todo y a칰n as칤 no llegaron a las eliminatorias o playoffs, lo que ser치 bueno para modelar.

쮺u치nto influye el *margin_of_victory*, una medida de los puntos anotados en relaci칩n con los puntos p칠rdidos, para llegar a los playoffs o eliminatorias?

```{r histograma, warning=FALSE, fig.height=7, fig.width=10, fig.show = "hold", fig.align='center'}
attendance_joined %>%
  distinct(team_name, year, margin_of_victory, playoffs) %>%
  ggplot(aes(margin_of_victory, fill = playoffs)) +
  geom_histogram(position = "identity", alpha = 0.7) +
  labs(
    x = "Margen de victoria",
    y = "N칰mmero de equipos",
    fill = NULL
  )


```


### 쮿ay cambios en cada semana de la temporada?

```{r boxplot, warning=FALSE, fig.height=5, fig.width=8, fig.show = "hold", fig.align='center'}
attendance_joined %>%
  mutate(week = factor(week)) %>%
  ggplot(aes(week, weekly_attendance, fill = week)) +
  geom_boxplot(show.legend = FALSE, outlier.alpha = 0.5) +
  labs(
    x = "Semana de la temporada de la NFL",
    y = "Asistencia semanal de juegos de la NFL"
  )
```

Hemos realizado un breve an치lisis exploratorio de datos, el cual siempre es una parte importante de la tarea de modelado. El siguiente paso es generar un conjunto de datos para modelar.


Eliminemos las semanas que cada equipo no jug칩 (es decir, donde la asistencia semanal es NA).
Conservemos 칰nicamente las columnas que queremos usar para el modelado. Por ejemplo, mantendremos *margin_of_victory* y *Strength_of_schedule*, pero no *simple_rating*, que es la suma de esas dos primeras cantidades.


```{r elimino_na, message=FALSE, warning=FALSE}
attendance_df <- attendance_joined %>%
  filter(!is.na(weekly_attendance)) %>%
  select(
    weekly_attendance, team_name, year, week,
    margin_of_victory, strength_of_schedule, playoffs
  )
attendance_df
attendance_df_new <- attendance_df %>% drop_na()
attendance_df_new
```


## Modelos simples con tidymodels

춰Ahora es el momento de cargar el metapaquete tidymodels! 游눩 El primer paso aqu칤 es dividir nuestros datos en pruebas de entrenamiento y pruebas. Podemos usar **initial_split ()** para crear estos conjuntos de datos, divididos para que cada uno tenga aproximadamente la misma cantidad de ejemplos de equipos que pasaron a los playoffs.


```{r division_datos, message=FALSE, warning=FALSE}
library(tidymodels)  #rsample

set.seed(1234)
attendance_split <- attendance_df_new %>%
  initial_split(strata = playoffs)

nfl_train <- training(attendance_split)
nfl_test <- testing(attendance_split)

nfl_test
nfl_train
```

## Ajuste del modelo utilizando **lm**

```{r regresion_lineal, message=FALSE, warning=FALSE}
lm_spec <- linear_reg() %>%   #parsnip
  set_engine(engine = "lm")

lm_spec
## Linear Regression Model Specification (regression)
##
## Computational engine: lm
lm_fit <- lm_spec %>%
  fit(weekly_attendance ~ .,
    data = nfl_train)

lm_fit

```

Ya fiteamos el primer modelo, ahora vamos por el segundo.

```{r random_forest, message=FALSE, warning=FALSE }

rf_spec <- rand_forest(mode = "regression") %>%
  set_engine("ranger")

rf_spec

```

## Ajuste del modelo utilizando **random forest**

```{r}
library('ranger')
rf_fit <- rf_spec %>%
  fit(weekly_attendance ~ ., data = nfl_train)

rf_fit

```

Observe que hemos ajustado ambos modelos utilizando nfl_train, es decir, los datos de entrenamiento. No hemos tocado los datos de las pruebas durante el entrenamiento.


## Evaluaci칩n de los modelos
Cuando sea el momento de evaluar nuestros modelos (para estimar qu칠 tan bien funcionar치n nuestros modelos con datos nuevos), analizaremos **nfl_test**. Podemos predecir cu치l ser치 la asistencia semanal tanto para los datos de entrenamiento como para los datos de prueba utilizando los modelos lm y de bosque aleatorio. Uno de los objetivos de tidymodels es poder utilizar c칩digo como el siguiente de formas predecibles y coherentes para muchos tipos de modelos, y utilizar las herramientas de tidyverse adecuadas para este tipo de tareas.


```{r resultados, message=FALSE, warning=FALSE}
results_train <- lm_fit %>%
  predict(new_data = nfl_train) %>%
  mutate(
    truth = nfl_train$weekly_attendance,
    model = "lm"
  ) %>%
  bind_rows(rf_fit %>%
    predict(new_data = nfl_train) %>%
    mutate(
      truth = nfl_train$weekly_attendance,
      model = "rf"
    ))

results_test <- lm_fit %>%
  predict(new_data = nfl_test) %>%
  mutate(
    truth = nfl_test$weekly_attendance,
    model = "lm"
  ) %>%
  bind_rows(rf_fit %>%
    predict(new_data = nfl_test) %>%
    mutate(
      truth = nfl_test$weekly_attendance,
      model = "rf"
    ))
results_test
```

Para este modelo de regresi칩n, veamos el **rmse** o erroc cuadr치tico medio de lo que hemos hecho hasta ahora.

```{r resultado_rsme_train, message=FALSE, warning=FALSE}
results_train %>%
  group_by(model) %>%
  rmse(truth = truth, estimate = .pred) %>% view

```

```{r resultado_rsme_test, message=FALSE, warning=FALSE}
results_test %>%
  group_by(model) %>%
  rmse(truth = truth, estimate = .pred) %>% view
results_test
```


## 쯄alas decisiones?
Si miramos los datos de entrenamiento, el modelo de bosque aleatorio funcion칩 mucho mejor que el modelo lineal; el rmse es mucho menor. Sin embargo, no se puede decir lo mismo de los datos de prueba. 游땴 La m칠trica para el entrenamiento y las pruebas para el modelo lineal es aproximadamente la misma, lo que significa que no hemos sobreajustado. Para el modelo de bosque aleatorio, la rmse es mucho m치s alta para los datos de prueba que para los datos de entrenamiento. Nuestros datos de entrenamiento no nos dan una buena idea de c칩mo funcionar치 nuestro modelo, y este poderoso algoritmo ML se ha sobreajustado a este conjunto de datos.


```{r grafico_resultado_test, echo=TRUE, fig.align='center', fig.height=5, fig.show="hold", fig.width=8, message=FALSE, warning=FALSE}
results_test %>%
  mutate(train = "testing") %>%
  bind_rows(results_train %>%
    mutate(train = "training")) %>%
  ggplot(aes(truth, .pred, color = model)) +
  geom_abline(lty = 2, color = "gray80", size = 1.5) +
  geom_point(alpha = 0.5) +
  facet_wrap(~train) +
  labs(
    x = "Valor real",
    y = "Asitencia predicha",
    color = "Tipo de modelo"
  )

```

## Intentemos mejorar el modelo
No tomamos una decisi칩n tan buena en la secci칩n anterior; esper치bamos que el modelo de bosque aleatorio evaluado una vez en todo el conjunto de entrenamiento nos ayudara a comprender algo sobre c칩mo funcionar칤a con nuevos datos. Esta ser칤a una expectativa razonable para el modelo lineal, pero no para el bosque aleatorio. Afortunadamente, tenemos algunas opciones. Podemos volver a muestrear el conjunto de entrenamiento para producir una estimaci칩n de c칩mo funcionar치 el modelo. Dividamos nuestro conjunto de entrenamiento nfl_train en pliegues (digamos, 10) y ajustemos 10 versiones de nuestro modelo (cada una entrenada en nueve pliegues y evaluada en un pliegue retenido). Luego, midamos qu칠 tan bien se desempe침an nuestros modelos. La funci칩n **vfold_cv ()** crea pliegues para validaci칩n cruzada, la funci칩n **fit_resamples ()** ajusta modelos a remuestreos como estos (para medir el desempe침o), y luego podemos recolectar_metrics () del resultado.



```{r resampleo, echo=TRUE, message=FALSE, warning=FALSE}
set.seed(1234)
nfl_folds <- vfold_cv(nfl_train, strata = playoffs)

rf_res <- fit_resamples(
  weekly_attendance ~ .,
  rf_spec,
  nfl_folds,
  control = control_resamples(save_pred = TRUE)
)

rf_res %>%
  collect_metrics() %>% view()


```

Recuerde que este sigue siendo el conjunto de datos de entrenamiento. Dar칤amos este paso en lugar del fragmento anterior con predecir (new_data = nfl_train), y a칰n comparar칤amos el rendimiento del modelo en los datos de prueba. Tenga en cuenta que ahora tenemos una estimaci칩n realista de los datos de entrenamiento que se acerca a los datos de prueba. Incluso podemos visualizar los resultados de nuestro modelo para los remuestreos.

```{r  grafico_final, echo=TRUE, fig.align='center', fig.height=5, fig.show="hold", fig.width=8, message=FALSE, warning=FALSE}
rf_res %>%
  unnest(.predictions) %>%
  ggplot(aes(weekly_attendance, .pred, color = id)) +
  geom_abline(lty = 2, color = "gray80", size = 1.5) +
  geom_point(alpha = 0.5) +
  labs(
    x = "Valor real",
    y = "Asistencia del juego predicha",
    color = NULL
  )
```

## Regularizaci칩n con Lasso

## Pre-procesamientocon recipe: opci칩n 1
```{r}
nfl_train2 <-nfl_train %>% select(weekly_attendance, margin_of_victory, strength_of_schedule, week)


nfl_rec <- recipe(weekly_attendance ~ ., data = nfl_train2) %>%      
  step_zv(all_numeric(), -all_outcomes()) %>%
  step_normalize(all_numeric(), -all_outcomes())

nfl_rec


```

## Pre-procesamientocon recipe:: opci칩n 2

```{r}
nfl_rec2 <- recipe(weekly_attendance ~ ., data = nfl_train) %>%
  update_role(team_name, new_role = "ID") %>%
  step_zv(all_numeric(), -all_outcomes()) %>%
  step_normalize(all_numeric(), -all_outcomes())

nfl_prep <- nfl_rec2 %>%
  prep(strings_as_factors = FALSE)
```

## Especifico el modelo

```{r}
install.packages("glmnet")
install.packages("Matrix")
library(Matrix)
library(glmnet)
lasso_spec <- linear_reg(penalty = 0.1, mixture = 1) %>%  set_engine("glmnet")

#-----------------------------------------------
# con recipe 1
wf_nfl <- workflow() %>%   # con recipe 1
  add_recipe(nfl_rec)


lasso_fit <- wf_nfl %>%
  add_model(lasso_spec) %>%
  fit(data = nfl_train)

lasso_fit %>%
  pull_workflow_fit() %>%
  tidy()

#-----------------------------------------------
# con recipe 2
wf_nfl2 <- workflow() %>%  # con recipe 2
  add_recipe(nfl_rec2)

lasso_fit2 <- wf_nfl2 %>%
  add_model(lasso_spec) %>%
  fit(data = nfl_train)

lasso_fit2 %>%
  pull_workflow_fit() %>%
  tidy()
```

## Tuneo con bootstrap

```{r}
set.seed(1234)
nfl_boot <- bootstraps(nfl_train, strata = playoffs)

tune_spec <- linear_reg(penalty = tune(), mixture = 1) %>%
  set_engine("glmnet")

lambda_grid <- grid_regular(penalty(), levels = 50)
```


```{r}
doParallel::registerDoParallel()

set.seed(2020)
lasso_grid <- tune_grid(
  wf_nfl %>% add_model(tune_spec),
  resamples = nfl_boot,
  grid = lambda_grid
)
# resultados

lasso_grid %>% collect_metrics()
```

## Grafico

```{r}
lasso_grid %>%
  collect_metrics() %>%
  ggplot(aes(penalty, mean, color = .metric)) +
  geom_errorbar(aes(
    ymin = mean - std_err,
    ymax = mean + std_err
  ),
  alpha = 0.5
  ) +
  geom_line(size = 1.5) +
  facet_wrap(~.metric, scales = "free", nrow = 2) +
  #scale_x_log10() +
  theme(legend.position = "none")
```


```{r}
lowest_rmse <- lasso_grid %>%
  select_best("rmse")

final_lasso <- finalize_workflow(
  wf_nfl %>% add_model(tune_spec),
  lowest_rmse
)
```


```{r}
last_fit(
  final_lasso,
  nfl_test
) %>%
  collect_metrics()
```


## Referencias:
 * [Blog de Julia Silge](https://juliasilge.com/blog/intro-tidymodels/)
 
 * [Sitio de Tidymodels](https://www.tidymodels.org/)
 
 * [Machine Learning con R y tidymodels](https://www.cienciadedatos.net/documentos/59_machine_learning_con_r_y_tidymodels#divisi%C3%B3n_train_y_test)

