---
title: "Regresi칩n con datos de NFL_attendance"
author: "Basado en el blog de Julia Silge"
date: "29/9/2020"
output: 
  html_document:
     css: xaringan-themer.css
     dev: png
     highlight: "default"
     toc: true
     toc_float: true
     code_folding: hide
---



```{r librerias-utiles, setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggthemes)
library(hrbrthemes)
theme_set(theme_fivethirtyeight())

```



## Dataset

Utilizaremos los datos de [#Tidytuesday](https://github.com/rfordatascience/tidytuesday), la cual es una iniciativa de la comunidad de R, en la cual se publica semanalmente un set de datos con el objetivo de practicar las habilidades de procesamiento, visualizaci칩n y modelado de datos. El dataset elegido contiene datos de la NFL, liga de f칰tbol americano de USA.

## Lectura de datos

```{r nfl_attandance, include=FALSE}
attendance <- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-04/attendance.csv")
standings <- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-04/standings.csv")

```
```{r vista-dataset}
attendance %>% glimpse()
standings %>%  glimpse()

```


## Uni칩n de los datasets

Ya le칤mos el dataset *attendance* y *standings*:

- attendance: datos de la asistencia semanal de los equipos. 

- standings: datos de la clasificaci칩n de los equipos con sus respectivas marcas. 

A continuaci칩n vamos a unir ambos datasets utilizando la sentencia **left_join** y mediante las siguientes variables: **c("year", "team_name", "team"))**



```{r union_datasets, echo=FALSE, message=FALSE, warning=FALSE}

attendance_joined <- attendance %>%
  left_join(standings,
    by = c("year", "team_name", "team")
  )

attendance_joined %>% view()
```


## Objetivo
Nuestro objetivo es obtener un modelo capaz predecir la asistencia semanal o 'weekly_attendance' a la NFL a partir del conjunto de datos #TidyTuesday. Hasta ahora, sabemos que es necesario utilizar modelos de regresi칩n.


## An치lisis exploratorio inicial

```{r boxplot-inicial, echo=FALSE, message=FALSE, warning=FALSE, fig.height=7, fig.width=10, fig.show = "hold", fig.align='center'}

attendance_joined %>%
  filter(!is.na(weekly_attendance)) %>%
  ggplot(aes(fct_reorder(team_name, weekly_attendance),
    weekly_attendance,
    fill = playoffs)) +
  geom_boxplot(outlier.alpha = 0.5) +
  coord_flip() +
  labs(
    fill = NULL, x = NULL,
    y = "Asistencia semanal de juegos de la NFL"
  )

# playoffs: eliminatorias, columna que contiene 2 posibles valores: eliminado y no eliminado.
```





Tengamos en cuenta que para los 32 equipos de la NFL, existen a침os en que lo dieron todo y a칰n as칤 no llegaron a las eliminatorias o playoffs, lo que ser치 bueno para modelar.

### 쮺u치nto influye el 췂margin_of_victory췂, una medida de los puntos anotados en relaci칩n con los puntos p칠rdidos, para llegar a los playoffs o eliminatorias?

```{r histograma, warning=FALSE, fig.height=7, fig.width=10, fig.show = "hold", fig.align='center'}
attendance_joined %>%
  distinct(team_name, year, margin_of_victory, playoffs) %>%
  ggplot(aes(margin_of_victory, fill = playoffs)) +
  geom_histogram(position = "identity", alpha = 0.7) +
  labs(
    x = "Margen de victoria",
    y = "N칰mmero de equipos",
    fill = NULL
  )


```


### 쮿ay cambios en cada semana de la temporada?

```{r boxplot, warning=FALSE, fig.height=5, fig.width=8, fig.show = "hold", fig.align='center'}
attendance_joined %>%
  mutate(week = factor(week)) %>%
  ggplot(aes(week, weekly_attendance, fill = week)) +
  geom_boxplot(show.legend = FALSE, outlier.alpha = 0.5) +
  labs(
    x = "Semana de la temporada de la NFL",
    y = "Asistencia semanal de juegos de la NFL"
  )
```

Hemos realizado un breve an치lisis exploratorio de datos, el cual siempre es una parte importante de la tarea de modelado. El siguiente paso es generar un conjunto de datos para modelar.


Eliminemos las semanas que cada equipo no jug칩 (es decir, donde la asistencia semanal es NA).
Conservemos 칰nicamente las columnas que queremos usar para el modelado. Por ejemplo, mantendremos *margin_of_victory* y *Strength_of_schedule*, pero no *simple_rating*, que es la suma de esas dos primeras cantidades.


```{r elimino_na, message=FALSE, warning=FALSE}
attendance_df <- attendance_joined %>%
  filter(!is.na(weekly_attendance)) %>%
  select(
    weekly_attendance, team_name, year, week,
    margin_of_victory, strength_of_schedule, playoffs
  )
attendance_df
attendance_df_new <- attendance_df %>% drop_na()
attendance_df_new
```


## Modelos simples con tidymodels

춰Ahora es el momento de cargar el metapaquete tidymodels! 游눩 El primer paso aqu칤 es dividir nuestros datos en pruebas de entrenamiento y pruebas. Podemos usar **initial_split ()** para crear estos conjuntos de datos, divididos para que cada uno tenga aproximadamente la misma cantidad de ejemplos de equipos que pasaron a los playoffs.


```{r division_datos, message=FALSE, warning=FALSE}
library(tidymodels)  #rsample

set.seed(1234)
attendance_split <- attendance_df_new %>%
  initial_split(strata = playoffs)

nfl_train <- training(attendance_split)
nfl_test <- testing(attendance_split)

nfl_test
nfl_train
```

## Especificaci칩n del modelo **lm**

```{r regresion_lineal, message=FALSE, warning=FALSE}
lm_spec <- linear_reg() %>%   #parsnip
  set_engine(engine = "lm")

```

## Ajuste del modelo utilizando **lm**
```{r ajuste_lm, message=FALSE, warning=FALSE}
lm_fit <- lm_spec %>%
  fit(weekly_attendance ~ .,
    data = nfl_train)

lm_fit
```




Ya fiteamos el primer modelo, ahora vamos por el segundo.

```{r random_forest, message=FALSE, warning=FALSE }

rf_spec <- rand_forest(mode = "regression") %>%
  set_engine("ranger")

rf_spec

```


## Ajuste del modelo utilizando **random forest**

```{r}
library('ranger')
rf_fit <- rf_spec %>%
  fit(weekly_attendance ~ ., data = nfl_train)

rf_fit

```

Aclaraci칩n: hemos ajustado ambos modelos utilizando 췂nfl_train췂, es decir, los datos de entrenamiento. No hemos tocado los datos de las pruebas durante el entrenamiento.


## Evaluaci칩n de los modelos
Cuando sea el momento de evaluar nuestros modelos (para estimar qu칠 tan bien funcionar치n nuestros modelos con datos nuevos), analizaremos **nfl_test**. Podemos predecir cu치l ser치 la asistencia semanal a los partidos de la NFL tanto para los datos de entrenamiento como para los datos de prueba utilizando los modelos lm y de random forest. Uno de los objetivos de tidymodels es poder utilizar c칩digo como el siguiente de formas predecibles y coherentes para muchos tipos de modelos, y utilizar las herramientas de tidyverse adecuadas para este tipo de tareas.


```{r resultados, message=FALSE, warning=FALSE}
results_train <- lm_fit %>%
  predict(new_data = nfl_train) %>%
  mutate(
    truth = nfl_train$weekly_attendance,
    model = "lm"
  ) %>%
  bind_rows(rf_fit %>%
    predict(new_data = nfl_train) %>%
    mutate(
      truth = nfl_train$weekly_attendance,
      model = "rf"
    ))

results_test <- lm_fit %>%
  predict(new_data = nfl_test) %>%
  mutate(
    truth = nfl_test$weekly_attendance,
    model = "lm"
  ) %>%
  bind_rows(rf_fit %>%
    predict(new_data = nfl_test) %>%
    mutate(
      truth = nfl_test$weekly_attendance,
      model = "rf"
    ))
results_test
```

Para este modelo de regresi칩n, la m칠trica que tendremos en cuenta para evaluar el modelo es el **rmse** o la ra칤z del error cuadr치tico medio de lo que hemos hecho hasta ahora.

```{r resultado_rsme_train, message=FALSE, warning=FALSE}
results_train %>%
  group_by(model) %>%
  rmse(truth = truth, estimate = .pred) %>% view

```

```{r resultado_rsme_test, message=FALSE, warning=FALSE}
results_test %>%
  group_by(model) %>%
  rmse(truth = truth, estimate = .pred) #%>% view
results_test
```


## 쯄alas decisiones?
Si miramos los datos de entrenamiento, el modelo de bosque aleatorio funcion칩 mucho mejor que el modelo lineal; el rmse es mucho menor. Sin embargo, no se puede decir lo mismo de los datos de prueba. 游땴 La m칠trica para el entrenamiento y las pruebas para el modelo lineal es aproximadamente la misma, lo que significa que no hemos sobreajustado. Para el modelo de bosque aleatorio, la rmse es mucho m치s alta para los datos de prueba que para los datos de entrenamiento. Nuestros datos de entrenamiento no nos dan una buena idea de c칩mo funcionar치 nuestro modelo, y este poderoso algoritmo ML se ha sobreajustado a este conjunto de datos.


```{r grafico_resultado_test, echo=TRUE, fig.align='center', fig.height=5, fig.show="hold", fig.width=8, message=FALSE, warning=FALSE}
results_test %>%
  mutate(train = "testing") %>%
  bind_rows(results_train %>%
    mutate(train = "training")) %>%
  ggplot(aes(truth, .pred, color = model)) +
  geom_abline(lty = 2, color = "gray80", size = 1.5) +
  geom_point(alpha = 0.5) +
  facet_wrap(~train) +
  labs(
    x = "Valor real",
    y = "Asitencia predicha",
    color = "Tipo de modelo"
  )

```



## Referencias:
 * [Blog de Julia Silge](https://juliasilge.com/blog/intro-tidymodels/)
 
 * [Sitio de Tidymodels](https://www.tidymodels.org/)
 
 * [Machine Learning con R y tidymodels](https://www.cienciadedatos.net/documentos/59_machine_learning_con_r_y_tidymodels#divisi%C3%B3n_train_y_test)

